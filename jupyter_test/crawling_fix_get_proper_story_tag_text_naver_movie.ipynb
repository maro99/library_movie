{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pic_url: https://movie-phinf.pstatic.net/20190306_280/1551849045570X4iac_JPEG/movie_image.jpg?type=m77_110_2\n",
      "pic_url: https://movie-phinf.pstatic.net/20190208_197/1549586594982x70KK_JPEG/movie_image.jpg?type=m427_320_2\n",
      "rating: 7.58\n",
      "genre: 범죄\n",
      "director: 박누리\n",
      "age: 15세 관람가\n",
      "story: 오직 부자가 되고 싶은 꿈을 품고 여의도 증권가에 입성한 신입 주식 브로커 조일현(류준열).  빽도 줄도 없는, 수수료 O원의 그는 곧 해고 직전의 처지로 몰린다. 위기의 순간, 베일에 싸인 신화적인 작전 설계자 번호표(유지태)를 만나게 되고,  막대한 이익을 챙길 수 있는 거래 참여를 제안 받는다.  위험한 제안을 받아들인 후 순식간에 큰 돈을 벌게 되는 일현.  승승장구하는 일현 앞에 번호표의 뒤를 쫓던 금융감독원의 사냥개 한지철(조우진)이 나타나  그를 조여 오기 시작하는데…\n"
     ]
    }
   ],
   "source": [
    "# @ 크롤링시 이상한 이미지, 정보들 들어가는 문제~ \n",
    "# 나온거 페이지 안에서 다 비교후 가장 참여 많은것 을 크롤링 하자.   \n",
    "\n",
    "\n",
    "title = '돈'\n",
    "\n",
    "from urllib import parse\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import urllib.request as req\n",
    "\n",
    "def get_soup(url):\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "    res = req.urlopen(url)\n",
    "    soup = BeautifulSoup(res, 'lxml')\n",
    "    return soup\n",
    "\n",
    "# 한글을 query 로 변환\n",
    "title_encoded = parse.quote(title)\n",
    "\n",
    "# 검색 url접속후 detail 페이지로 가기위한 url을 먼저 얻겠다.\n",
    "url = \"https://movie.naver.com/movie/search/result.nhn?query=\" + title_encoded + \"&section=all&ie=utf8\"\n",
    "soup = get_soup(url)\n",
    "\n",
    "# 만약 아무것도 검색 결과 없다면 None 입력되고 아래 if문 못들어감.\n",
    "# detail_url_pre = soup.select_one('ul.search_list_1 > li > dl > dt > a')\n",
    "detail_url_pre = soup.select('ul.search_list_1 > li > dl > dd.point > em.cuser_cnt')\n",
    "\n",
    "if detail_url_pre: # 비면(검색결과 x) 아예 아래로 안가겠슴. \n",
    "    \n",
    "  # 모델 객체 저장할 값들 초기화\n",
    "        pic_url =\"\"\n",
    "        rating = 0\n",
    "        genre = \"\"\n",
    "        director =\"\"\n",
    "        age =\"\"\n",
    "        story =\"\"\n",
    "\n",
    "        # 이하는 검색 결과 중 가장 많이본 영화 테그 착기 위함.\n",
    "        max_num = 0\n",
    "        max_num_rated_movies_line1 = detail_url_pre[0]  # 일단 맨앞 line저장\n",
    "        for line1 in detail_url_pre:\n",
    "            #         print(line1) # 여기기준  이웃 , 부모 테그 타고가서 링크 얻자.\n",
    "            text_pre = line1.get_text()\n",
    "            number_of_rated_people = re.findall(\"(\\d+)\", text_pre)[0]\n",
    "            #         print(number_of_rated_people)\n",
    "            if max_num <= int(number_of_rated_people):\n",
    "                max_num = int(number_of_rated_people)\n",
    "                max_num_rated_movies_line1 = line1\n",
    "\n",
    "        parent_tag = max_num_rated_movies_line1.parent\n",
    "        dt_tag_as_previous_tag = parent_tag.find_previous_sibling(\"dt\")\n",
    "        a_tag = dt_tag_as_previous_tag.select_one('a')\n",
    "\n",
    "        # detail로 가는 url\n",
    "        detail_url = 'https://movie.naver.com' + a_tag.get('href')\n",
    "\n",
    "        soup = get_soup(detail_url)\n",
    "\n",
    "        # 포스터 이미지\n",
    "        pic_url_pre = soup.select_one('div.poster > a > img')\n",
    "        if pic_url_pre:\n",
    "            pic_url = pic_url_pre.get('src')\n",
    "            print(f'pic_url: {pic_url}')\n",
    "\n",
    "        # 포토가 있는 경우에는 포토 의 맨앞에거 가져다 쓰고싶다.\n",
    "        pic_viewer_url_pre = soup.select_one('div.viewer_img >  img')\n",
    "        if pic_viewer_url_pre:\n",
    "            pic_url = pic_viewer_url_pre.get('src')\n",
    "            print(f'pic_url: {pic_url}')\n",
    "\n",
    "        rating_pre = soup.select_one('div.mv_info > div.main_score > div.score.score_left > div.star_score > a')\n",
    "        if rating_pre:\n",
    "            rating = rating_pre.get_text()\n",
    "            print(f'rating: {rating}')\n",
    "\n",
    "\n",
    "        genre_pre_pre = soup.select_one('div.mv_info > dl.info_spec > dt.step1')\n",
    "        if genre_pre_pre:\n",
    "            genre_pre = genre_pre_pre.find_next_siblings('dd')[0].select('p > span > a')[0] # 여기서 인덱스 에러 날수도 있다...\n",
    "            if genre_pre:\n",
    "                genre =  genre_pre.get_text()\n",
    "                print(f'genre: {genre}')\n",
    "\n",
    "\n",
    "        director_pre_pre = soup.select_one('div.mv_info > dl.info_spec > dt.step2')\n",
    "        if director_pre_pre:\n",
    "            director_pre = director_pre_pre.find_next_siblings('dd')[0]\n",
    "            if director_pre:\n",
    "                director = director_pre.get_text()\n",
    "                print(f'director: {director}')\n",
    "\n",
    "\n",
    "        age_pre_pre = soup.select_one('div.mv_info > dl.info_spec > dt.step4')\n",
    "        if age_pre_pre:\n",
    "            age_pre = age_pre_pre.find_next_siblings('dd')[0].select_one('a')\n",
    "            if age_pre:\n",
    "                age = age_pre.get_text()\n",
    "                print(f'age: {age}')\n",
    "\n",
    "        story_pre = soup.select_one('div.story_area > p.con_tx')\n",
    "        \n",
    "#         print(story_pre)\n",
    "        \n",
    "        if story_pre:\n",
    "            story = story_pre.get_text()\n",
    "\n",
    "            # 제작노트 같이 크롤링 된다면 잘라서 저장 하겠다.\n",
    "\n",
    "\n",
    "            print(f'story: {story}')\n",
    "\n",
    "#         # # 썸네일이 이미 없는 경우에만 업데이트를 하자 ------> 일단 안지우겠슴.\n",
    "#         # if movie.thumbnail_url == \"\":\n",
    "#         #     movie.thumbnail_url = pic_url\n",
    "\n",
    "#         # 썸네일 네이버 검색 이미지 -> 뷰어이미지 첫번째거로 통일 시키겠다.\n",
    "#         # 무조건 업데이트 하겠슴.(검색 안되는데 섬네일 있는경우는 여기 아예 안들언옴) ---> 12.31/ get_or_create시 계속 중복 생성해서 걍 무조건 여기서 업데이트 하겠슴.\n",
    "#         movie.thumbnail_url = pic_url                                         # 검색 안되는것 추후 구글검색 첫이미지로 업데이트 시키겠다.\n",
    "\n",
    "#         # 수지윙의 세계의 경우 네이버 영화 에서 검색은 되지만 섬네일 없다.\n",
    "#         # 이런경우에는 구글에서 이미지 검색해서 썸네일 업데이트 해주자.\n",
    "#         if not pic_url:\n",
    "#             upadete_google_image(movie,movie.title)\n",
    "\n",
    "#         movie.rating = float(rating)\n",
    "#         movie.genre = genre\n",
    "#         movie.director = director\n",
    "#         movie.age = age\n",
    "#         movie.story = story\n",
    "#         movie.save()\n",
    "\n",
    "    # 네이버 영화에서 검색결과 없다면.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
