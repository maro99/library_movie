{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from urllib import parse\n",
    "import json\n",
    "from selenium import webdriver\n",
    "\n",
    "import datetime\n",
    "\n",
    "import ssl\n",
    "import urllib.request as req\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# 영화 제목 \n",
    "# 일시 \n",
    "# 장소 \n",
    "\n",
    "\n",
    "#     ##### 동대문구 크롤러##### (월별)\n",
    "def dongdaemungu_movie_crawler(libGroup):\n",
    "    \n",
    "    params = {\n",
    "        'libGroup': libGroup,\n",
    "    }\n",
    "    url = \"http://www.l4d.or.kr/library/index.php?g_page=culture&m_page=culture04&\" + parse.urlencode(params)\n",
    "\n",
    "    \n",
    "    request = requests.get(url)\n",
    "    response = request.text\n",
    "    soup = BeautifulSoup(response, 'lxml')\n",
    "    \n",
    "    # 영화별 정보 담은 박스 \n",
    "    data_boxes = soup.select('div.data_wrapper')\n",
    "\n",
    "    for data_box in data_boxes:\n",
    "        \n",
    "        # 사진 뽑기\n",
    "        pic_url = data_box.select_one('div.pic > a > img').get('src')\n",
    "        # 사진 url을 뽑아보니 두가지 경우가 있다. \n",
    "        # http로 시작 하는 경우, 상대결로로서 l4d주소 있다 가정하고 뒷주소만 있는경우\n",
    "        \n",
    "        # 뒷 주소만 있는경우 ../경로표시 빼고 l4d 주소 더해준다. \n",
    "        if not re.findall('http://',pic_url):\n",
    "            pic_url =  'http://www.l4d.or.kr/'+ re.findall('\\..(.*)',pic_url)[0]\n",
    "        \n",
    "        #@ 사진\n",
    "        print(f'pic_url: {pic_url}')\n",
    "        \n",
    "        #제목 뽑기 \n",
    "        title = data_box.select_one('h3.recom_title > a').get_text(strip=True)\n",
    "        #@ 제목 \n",
    "        print(f'title: {title}')\n",
    "        \n",
    "        # 나머지 정보들 뽑기.\n",
    "        \n",
    "#         print(data_box.prettify())\n",
    "        \n",
    "#         <li>\n",
    "#           <span class=\"fb\">\n",
    "#            일시\n",
    "#           </span>\n",
    "#           : 2018.09.02 13:00 (일)\n",
    "#          </li>\n",
    "#\n",
    "#          이런식으로 리스트들이 들어있는데 \n",
    "#          li를 자식인 span.fb의 text인 일시 를 기준으로 찾고 싶다. \n",
    "#          즉 기준이되는 찾은 테그의 부모의 택스트를 가져오고 싶은것.\n",
    "        \n",
    "        # 여기서 선택 된 것은 tag리스트이고 \n",
    "        # 이중 text가 일시 인것을 먼저 찾아보겠다. \n",
    "        \n",
    "\n",
    "        span_tags = data_box.select('ul > li > span.fb')\n",
    "#         print(span_tags)\n",
    "\n",
    "        when = \"\"#일시\n",
    "        place = \"\"#장소\n",
    "        runtime = \"\"#시간        # 만약에 해당 항목 없으면 \"\"\n",
    "        \n",
    "        for span_tag in span_tags:\n",
    "            span_tag_text = span_tag.get_text(strip=True)\n",
    "            \n",
    "            if span_tag_text == \"일시\":\n",
    "                when = span_tag.parent.get_text(strip=True)\n",
    "                #@ 일시\n",
    "                print(when)\n",
    "            \n",
    "            elif span_tag_text ==\"장소\":\n",
    "                place = span_tag.parent.get_text(strip=True)\n",
    "                #@ 장소 \n",
    "                print(place)\n",
    "                \n",
    "            elif span_tag_text ==\"시간\":\n",
    "                runtime = span_tag.parent.get_text(strip=True)\n",
    "                #@ 시간\n",
    "                print(runtime)\n",
    "                \n",
    "                \n",
    "        print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "\n",
    "        \n",
    "        \n",
    "#    ##### 성동구 크롤러 ##### (페이지별)\n",
    "\n",
    "def seongdonggu_movie_crawler(area_code,year):\n",
    "\n",
    "    \n",
    "    # 페이지 1~5를 탐색해서 해당 월에 상영하는 작품만 가져오자.\n",
    "    for page in range(1,6):\n",
    "        \n",
    "        params = {\n",
    "            'page':page\n",
    "        }\n",
    "\n",
    "        url = \"https://www.sdlib.or.kr/\"+ area_code + \"/U07080.asp?viewtype=list&\" + parse.urlencode(params)\n",
    "#     url = \"https://www.sdlib.or.kr/SD/U07080.asp?viewtype=list&page=1&libno=\"\n",
    "\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "        res = req.urlopen(url)\n",
    "        soup = BeautifulSoup(res, 'lxml')\n",
    "\n",
    "        table_rows = soup.select('table.table700 > tbody > tr')\n",
    "\n",
    "\n",
    "        for row in table_rows:\n",
    "            for index, td in enumerate(row.select('td')):\n",
    "                if index == 0:\n",
    "                    print(f'time_date : {td.get_text(strip=True)}') #날짜 \n",
    "                elif index ==2:\n",
    "                    print(f'time_hour : {td.get_text(strip=True)}') # 시작시간 \n",
    "                elif index ==3:\n",
    "                    print(f'title : {td.get_text(strip=True)}') # 영화 제목\n",
    "                elif index ==6:\n",
    "                    print(f'runtime :  {td.get_text(strip=True)}') # 상영시간 \n",
    "\n",
    "            print('@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "            \n",
    "        print(f'{page}@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def gwangjingu_movie_crawler(area_code,year):\n",
    "    \n",
    "    def get_soup(url):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "        res = req.urlopen(url)\n",
    "        soup = BeautifulSoup(res, 'lxml')    \n",
    "        return soup\n",
    "        \n",
    "    if area_code == 'gjinfo':\n",
    "        url = \"https://www.gwangjinlib.seoul.kr/gjinfo/menu/10087/program/30020/movieList.do\"\n",
    "        soup = get_soup(url)\n",
    "        \n",
    "        movies = soup.select('ul.movie-list > li')\n",
    "        for movie in movies:\n",
    "            photo_url = \"https://www.gwangjinlib.seoul.kr\" + movie.select_one('div.thumb > img').get('src')\n",
    "#             print(photo_url) # 사진 \n",
    "            title =  movie.select_one('dl > dt')\n",
    "            print(title.contents[1].strip()) # 제목\n",
    "            dds = movie.select('dl > dd')\n",
    "            for index, dd in enumerate(dds):\n",
    "                if index ==1:\n",
    "                    print(f'런타임: {dd.contents[1].strip()}') # 런타임\n",
    "                \n",
    "                elif index ==3:\n",
    "#                     print(f'상영일자 : {dd.contents[1]}') #상영일자(날짜 + 시간 ) # 2018.10.27(토) 오후 2시 or 오후2시, 오전1시 \n",
    "                    when = dd.contents[1]\n",
    "                    when_date = re.findall(\"(\\S*)\\(\",when)[0]\n",
    "                    print(f'상영 날짜 : {when_date}') # 상영 날짜  # 2018.10.27\n",
    "\n",
    "                    when_time_pre = re.findall(\"\\)\\s*(.{4,6})시\",when)[0]\n",
    "#                     print(f'상영 시간 : {when_time_pre}') # 상영 시간  # 오후 2시\n",
    "                    if '오후' in when_time_pre:\n",
    "                        when_time = int(re.findall(\"오후(.*\\d*)\",when_time_pre)[0].strip()) +12\n",
    "\n",
    "                    elif '오전' in when_time_pre:\n",
    "                        when_time = int(re.findall(\"오전(.*\\d*)\",when_time_pre)[0].strip())\n",
    "                    \n",
    "                    print(f'상영 시간 :{when_time}')\n",
    "                        \n",
    "                    print('@@@@@@@@@@@@@@@@@@')\n",
    "                    \n",
    "                    \n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "    elif area_code == 'jgsports':\n",
    "        url = \"https://www.gwangjinlib.seoul.kr/jgsports/menu/11005/program/30201/eventList.do\"\n",
    "        soup = get_soup(url)\n",
    "        \n",
    "    elif area_code == 'gu3dong':\n",
    "        url = \"https://www.gwangjinlib.seoul.kr/gu3dong/menu/11002/program/30202/eventList.do\"\n",
    "        soup = get_soup(url)\n",
    "\n",
    "    table_rows = soup.select('table.table700 > tbody > tr')\n",
    "\n",
    "\n",
    "\n",
    "def main_movie_crawler():\n",
    "    \n",
    "    # 오늘 날짜 먼저 가져옴 \n",
    "    now = datetime.datetime.now()\n",
    "    year = now.year\n",
    "    day = now.day\n",
    "    month = now.month\n",
    "\n",
    "    \n",
    "#     ##### 동대문구 크롤러##### \n",
    "\n",
    "#     dongdaemungu_area_code_list = ['MA','MF','MB','MC','MJ'] \n",
    "#     # 정보화,답십리, 장안, 용두, 휘셩 (이문 제외)\n",
    "# #     dongdaemungu_area_code_list = ['MA']\n",
    "    \n",
    "#     for libGroup in dongdaemungu_area_code_list:\n",
    "#         dongdaemungu_movie_crawler(libGroup)\n",
    "#         print(f'{libGroup} #####################################################################################################################################')\n",
    "\n",
    "\n",
    "\n",
    "#     ##### 성동구 크롤러 #####\n",
    "    \n",
    "#     seongdonggu_area_code_list = ['SD','YD','SS','KH','CG'] \n",
    "#     # 성동구립,용답, 장안, 성수, 금호,청계\n",
    "# #     seongdonggu_area_code_list = ['SD']\n",
    "    \n",
    "#     for area_code in seongdonggu_area_code_list:\n",
    "#         seongdonggu_movie_crawler(area_code,year)\n",
    "#         print(f'{area_code}#############################################################################################################################')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ##### 광진구 크롤러 #####\n",
    "    gwangjingu_area_code_list = ['gjinfo','jgsports','gu3dong']\n",
    "#     정보 , 중곡문화체육센터, 구의제3동 \n",
    "    for area_code in gwangjingu_area_code_list:\n",
    "        gwangjingu_movie_crawler(area_code,year)\n",
    "        print(f'{area_code}#############################################################################################################################')\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행복의 나라\n",
      "런타임: 86분\n",
      "상영 날짜 : 2018.10.06\n",
      "상영 시간 :11\n",
      "@@@@@@@@@@@@@@@@@@\n",
      "암살\n",
      "런타임: 139분\n",
      "상영 날짜 : 2018.10.06\n",
      "상영 시간 :14\n",
      "@@@@@@@@@@@@@@@@@@\n",
      "토마스와 친구들:용감한 기관차와 괴물소동\n",
      "런타임: 60분\n",
      "상영 날짜 : 2018.10.07\n",
      "상영 시간 :11\n",
      "@@@@@@@@@@@@@@@@@@\n",
      "수성못\n",
      "런타임: 88분\n",
      "상영 날짜 : 2018.10.13\n",
      "상영 시간 :11\n",
      "@@@@@@@@@@@@@@@@@@\n",
      "위험한 상견례2\n",
      "런타임: 119분\n",
      "상영 날짜 : 2018.10.13\n",
      "상영 시간 :14\n",
      "@@@@@@@@@@@@@@@@@@\n",
      "오즈의 마법사: 돌아온 도로시\n",
      "런타임: 92분\n",
      "상영 날짜 : 2018.10.14\n",
      "상영 시간 :11\n",
      "@@@@@@@@@@@@@@@@@@\n",
      "파파좀비\n",
      "런타임: 89분\n",
      "상영 날짜 : 2018.10.20\n",
      "상영 시간 :11\n",
      "@@@@@@@@@@@@@@@@@@\n",
      "스톰 인사이드\n",
      "런타임: 83분\n",
      "상영 날짜 : 2018.10.20\n",
      "상영 시간 :11\n",
      "@@@@@@@@@@@@@@@@@@\n",
      "꼬마잠수함 올리2\n",
      "런타임: 72분\n",
      "상영 날짜 : 2018.10.21\n",
      "상영 시간 :11\n",
      "@@@@@@@@@@@@@@@@@@\n",
      "여자들\n",
      "런타임: 101분\n",
      "상영 날짜 : 2018.10.27\n",
      "상영 시간 :11\n",
      "@@@@@@@@@@@@@@@@@@\n",
      "미션 임파서블: 로그네이션\n",
      "런타임: 131분\n",
      "상영 날짜 : 2018.10.27\n",
      "상영 시간 :14\n",
      "@@@@@@@@@@@@@@@@@@\n",
      "천년여우 여우비\n",
      "런타임: 85분\n",
      "상영 날짜 : 2018.10.28\n",
      "상영 시간 :11\n",
      "@@@@@@@@@@@@@@@@@@\n",
      "우리 선생님을 고발합니다.\n",
      "런타임: 99분\n",
      "상영 날짜 : 2018.10.31\n",
      "상영 시간 :14\n",
      "@@@@@@@@@@@@@@@@@@\n",
      "gjinfo#############################################################################################################################\n",
      "jgsports#############################################################################################################################\n",
      "gu3dong#############################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "main_movie_crawler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
